import pandas as pd
import hashlib
import json
from typing import List, Dict, Tuple
from sqlalchemy import create_engine
import logging

class DatabaseMigrationValidator:
    def __init__(self, source_url: str, target_url: str):
        """
        Initialize the validator with source and target database URLs.
        
        Args:
            source_url: SQLAlchemy URL for source database
            target_url: SQLAlchemy URL for target database
        """
        self.source_engine = create_engine(source_url)
        self.target_engine = create_engine(target_url)
        self.logger = logging.getLogger(__name__)

    def validate_table(self, table_name: str) -> Dict:
        """
        Validate data consistency between source and target tables.
        
        Args:
            table_name: Name of the table to validate
            
        Returns:
            Dictionary containing validation results and metrics
        """
        checkpoints = {
            "row_count_match": False,
            "column_match": False,
            "data_hash_match": False,
            "detailed_comparison": False
        }
        
        # Fetch data from both databases
        try:
            source_data = self._fetch_data(self.source_engine, table_name)
            target_data = self._fetch_data(self.target_engine, table_name)
        except Exception as e:
            self.logger.error(f"Error fetching data: {str(e)}")
            return {
                "is_valid": False,
                "error": f"Data fetch failed: {str(e)}",
                "checkpoints": checkpoints
            }

        # Checkpoint 1: Row count validation
        if len(source_data) != len(target_data):
            return {
                "is_valid": False,
                "error": "Row count mismatch",
                "source_count": len(source_data),
                "target_count": len(target_data),
                "checkpoints": checkpoints
            }
        checkpoints["row_count_match"] = True

        # Checkpoint 2: Column validation
        source_columns = set(source_data[0].keys()) if source_data else set()
        target_columns = set(target_data[0].keys()) if target_data else set()
        
        if source_columns != target_columns:
            return {
                "is_valid": False,
                "error": "Column mismatch",
                "source_columns": list(source_columns),
                "target_columns": list(target_columns),
                "checkpoints": checkpoints
            }
        checkpoints["column_match"] = True

        # Checkpoint 3: Data hash comparison
        source_hash = self._calculate_data_hash(source_data)
        target_hash = self._calculate_data_hash(target_data)
        
        checkpoints["data_hash_match"] = (source_hash == target_hash)
        
        if not checkpoints["data_hash_match"]:
            # Find specific differences if hashes don't match
            differences = self._find_differences(source_data, target_data)
            return {
                "is_valid": False,
                "error": "Data content mismatch",
                "differences": differences,
                "checkpoints": checkpoints
            }

        # Checkpoint 4: Detailed row-by-row comparison
        differences = self._find_differences(source_data, target_data)
        checkpoints["detailed_comparison"] = (len(differences) == 0)

        if differences:
            return {
                "is_valid": False,
                "error": "Detailed comparison failed",
                "differences": differences,
                "checkpoints": checkpoints
            }

        return {
            "is_valid": True,
            "message": "All validation checks passed",
            "checkpoints": checkpoints,
            "row_count": len(source_data),
            "data_hash": source_hash
        }

    def _fetch_data(self, engine, table_name: str) -> List[Dict[str, str]]:
        """
        Fetch data from database and convert to list of dictionaries.
        """
        query = f"SELECT * FROM {table_name}"
        df = pd.read_sql(query, engine)
        return df.to_dict('records')

    def _calculate_data_hash(self, data: List[Dict[str, str]]) -> str:
        """
        Calculate a deterministic hash of the data.
        """
        # Sort the data to ensure consistent ordering
        sorted_data = sorted(data, key=lambda x: json.dumps(x, sort_keys=True))
        data_str = json.dumps(sorted_data, sort_keys=True)
        return hashlib.sha256(data_str.encode()).hexdigest()

    def _find_differences(self, source_data: List[Dict[str, str]], 
                         target_data: List[Dict[str, str]]) -> List[Dict]:
        """
        Find specific differences between source and target data.
        """
        differences = []
        
        # Create dictionaries for faster lookup
        source_dict = {json.dumps(item, sort_keys=True): idx 
                      for idx, item in enumerate(source_data)}
        target_dict = {json.dumps(item, sort_keys=True): idx 
                      for idx, item in enumerate(target_data)}

        # Find items in source that don't match target
        for idx, source_item in enumerate(source_data):
            source_str = json.dumps(source_item, sort_keys=True)
            if source_str not in target_dict:
                differences.append({
                    "type": "mismatch",
                    "source_row": idx,
                    "source_data": source_item
                })

        # Find items in target that don't match source
        for idx, target_item in enumerate(target_data):
            target_str = json.dumps(target_item, sort_keys=True)
            if target_str not in source_dict:
                differences.append({
                    "type": "mismatch",
                    "target_row": idx,
                    "target_data": target_item
                })

        return differences[:10]  # Limit to first 10 differences

# Example usage
if __name__ == "__main__":
    # Example database URLs (modify according to your setup)
    source_url = "postgresql://user:pass@localhost:5432/source_db"
    target_url = "postgresql://user:pass@localhost:5432/target_db"
    
    validator = DatabaseMigrationValidator(source_url, target_url)
    
    # Validate a specific table
    result = validator.validate_table("your_table_name")
    print(json.dumps(result, indent=2))

#pip install pandas sqlalchemy psycopg2-binary

